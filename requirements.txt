appnope==0.1.3
asttokens==2.4.0
av==10.0.0
backcall==0.2.0
black==23.9.1
certifi==2023.7.22
cffi==1.16.0
charset-normalizer==3.3.0
click==8.1.7
coloredlogs==15.0.1
comm==0.1.4
ctranslate2==3.20.0
debugpy==1.8.0
decorator==5.1.1
diskcache==5.6.3
exceptiongroup==1.1.3
executing==2.0.0
faster-whisper==0.9.0
filelock==3.12.4
flatbuffers==23.5.26
fsspec==2023.9.2
huggingface-hub==0.17.3
humanfriendly==10.0
idna==3.4
importlib-metadata==6.8.0
ipykernel==6.25.2
ipython==8.16.1
jedi==0.19.1
jupyter_client==8.3.1
jupyter_core==5.3.2
-e git+https://github.com/abetlen/llama-cpp-python.git@43dfe1e2abef2ef0d873732ed65986eb9c3e379f#egg=llama_cpp_python
matplotlib-inline==0.1.6
mpmath==1.3.0
mypy-extensions==1.0.0
nest-asyncio==1.5.8
numpy==1.26.0
onnxruntime==1.16.1
packaging==23.2
parso==0.8.3
pathspec==0.11.2
pexpect==4.8.0
pickleshare==0.7.5
platformdirs==3.11.0
prompt-toolkit==3.0.39
protobuf==4.24.4
psutil==5.9.5
ptyprocess==0.7.0
pure-eval==0.2.2
pycparser==2.21
pydub==0.25.1
pygame==2.5.2
Pygments==2.16.1
python-dateutil==2.8.2
PyYAML==6.0.1
pyzmq==25.1.1
requests==2.31.0
six==1.16.0
sounddevice==0.4.6
stack-data==0.6.3
sympy==1.12
tokenizers==0.14.1
tornado==6.3.3
tqdm==4.66.1
traitlets==5.11.2
typing_extensions==4.8.0
urllib3==2.0.6
wcwidth==0.2.8
zipp==3.17.0
